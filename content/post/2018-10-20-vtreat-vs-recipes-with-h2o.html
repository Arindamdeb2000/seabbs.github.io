---
title: "Some thoughts on `vtreat` vs. `recipes` (+ `embed`) using `h2o` and `iml`"
author: 'null'
date: '2018-10-20'
description: ""
slug: vtreat-vs-recipes-with-h2o
draft: yes 
tags: ["data analysis", "data science", "rstats", "data cleaning", "h2o", "auto-ml"]
categories: ["R"]
twitterImg: ""
---



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Aim: Compare vtreat and recipes using h2o auto ml as baseline. Use messy data with some real world features.</p>
</div>
<div id="packages" class="section level2">
<h2>Packages</h2>
<p>First thing first we need to get the packages required. We do this using <code>pacman</code> to manange the installation process (note if struggling with the dependencies <a href="https://github.com/seabbs/seabbs.github.io/blob/sources/Dockerfile">see this dockerfile</a> for some clues - <a href="https://github.com/seabbs/seabbs.github.io">alternatively here is one I made earlier</a>).</p>
<pre class="r"><code>if (!require(pacman)) install.packages(&quot;pacman&quot;); library(pacman)
p_load(&quot;tidyverse&quot;)
p_load(&quot;broom&quot;)
p_load(&quot;purrr&quot;)
p_load(&quot;h2o&quot;)
p_load(&quot;vtreat&quot;)
p_load(&quot;recipes&quot;)
p_load(&quot;skimr&quot;)
p_load(&quot;embed&quot;)
p_load(&quot;knitr&quot;)
p_load_gh(&quot;thomasp85/patchwork&quot;, dependencies = TRUE)</code></pre>
</div>
<div id="data" class="section level2">
<h2>Data</h2>
<p>Data on loan defaults from <a href="https://github.com/gastonstat/CreditScoring">CreditScoring</a> via <a href="https://tidymodels.github.io/recipes/reference/credit_data.html"><code>recipes</code></a>.</p>
<pre class="r"><code>credit_data &lt;- recipes::credit_data %&gt;% 
  as_tibble  %&gt;% 
  mutate(id = 1:n())

skim(credit_data)</code></pre>
<p>Lets make the data more complex. The first step is to add some numeric noise variables on differing scales and categorical variables with many fields (10, 50, 100, 250, 500 and 1000).</p>
<pre class="r"><code>## Set up categorical variable generation
get_cat_noise_var &lt;- function(levels = NULL, samples) {
  sample(paste(&#39;level&#39;,1:levels,sep=&#39;&#39;), samples, replace=TRUE)
}

## Generate categorical variable with differing lengths (10, 100, 1000)
cat_noise_var &lt;- map(c(10, 50, 100, 250, 500, 1000), ~ rep(., 5)) %&gt;% 
  flatten %&gt;% 
  map_dfc(~get_cat_noise_var(., nrow(credit_data))) %&gt;% 
  set_names(paste0(&quot;CatNoise_&quot;, 1:30)) %&gt;% 
  map_dfc(factor)

## Set up numeric variable generation. Normal with random mean and standard deviation (or log normal)
get_num_noise_var &lt;- function(noise = 0.1, samples, log_shift = FALSE) {
  mean &lt;- runif(1, -1e3, 1e3)
  x &lt;- rnorm(samples, mean, abs(mean) * noise)
  
  if (log_shift) { 
   x &lt;- log(abs(x + 1))
  }
  
  return(x)
}

## Generate numeric variables with varying amounts of noise and transforming using log
gen_numeric_var &lt;- function(log_shift) {
  map(c(0.1, 0.2, 0.4), ~ rep(., 5)) %&gt;% 
  flatten %&gt;% 
  map_dfc( ~ get_num_noise_var(., nrow(credit_data), log_shift))
}

num_noise_var &lt;- gen_numeric_var(log_shift = FALSE) %&gt;% 
  bind_cols(gen_numeric_var(log_shift = TRUE)) %&gt;% 
    set_names(paste0(&quot;NumNoise_&quot;, 1:30))
  

## Bind together and summarise
noise_var &lt;- cat_noise_var %&gt;% 
  bind_cols(num_noise_var)


skim(noise_var)</code></pre>
<p>Add some missingness to the data and replace the home owners <code>&quot;other&quot;</code> category with 1000 random levels. Adding random noise levels to the home owners variable should be a good test of our data handling and the performance of the predictive models as ideally we want to use all the information encoded in the informative categories without overfitting to the uninformative noise categories.</p>
<pre class="r"><code>add_miss &lt;- function(x = NULL, max_miss = NULL) {
  miss_scale &lt;- runif(1, 0, max_miss)
  
  x &lt;- replace(x, runif(length(x), 0, 1) &lt;= miss_scale, NA)
}



complex_credit_data &lt;- credit_data %&gt;% 
  bind_cols(noise_var) %&gt;% 
  mutate_at(.vars = vars(everything(), - Status), ~ add_miss(., 0.1)) %&gt;% 
  mutate(
    Home = case_when(Home %in% &quot;other&quot; ~ as.character(CatNoise_30),
                          TRUE ~ as.character(Home)) %&gt;% 
           factor)
  
skim(complex_credit_data)</code></pre>
<ul>
<li>Split out test and training data (filtering joins (<code>semi_join</code> and <code>anti_join</code>) are the best new to me R function that I have come across recently).</li>
</ul>
<pre class="r"><code>train_complex &lt;- complex_credit_data %&gt;% 
  sample_frac(0.6)

train_simple &lt;- credit_data %&gt;% 
  semi_join(train_complex, by = &quot;id&quot;)

valid_complex&lt;-complex_credit_data %&gt;% 
  anti_join(train_complex, by = &quot;id&quot;) %&gt;% 
  sample_frac(0.5)

valid_simple &lt;- credit_data %&gt;% 
  semi_join(valid_complex, by = &quot;id&quot;)

test_complex &lt;- complex_credit_data %&gt;% 
  anti_join(train_complex, by = &quot;id&quot;) %&gt;% 
  anti_join(valid_complex, by = &quot;id&quot;)

test_simple &lt;- credit_data %&gt;% 
  semi_join(test_complex, by = &quot;id&quot;)</code></pre>
<ul>
<li>Set up target</li>
</ul>
<pre class="r"><code>target &lt;- &quot;Status&quot;</code></pre>
</div>
<div id="h2o" class="section level2">
<h2>H2o</h2>
<div id="set-up" class="section level3">
<h3>Set up</h3>
<ul>
<li>Outline what <code>h2o</code> is and why we are using it</li>
<li>Set up <code>h2o</code></li>
</ul>
<pre class="r"><code>h2o.init(nthreads = 4, min_mem_size = &quot;16G&quot;)

tune_time &lt;- 60 * 0.5</code></pre>
<ul>
<li>Setup <code>h2o</code> data.</li>
</ul>
<pre class="r"><code>h2o_train_complex &lt;- as.h2o(train_complex)
h2o_valid_complex &lt;- as.h2o(valid_complex)
h2o_train_simple &lt;- as.h2o(train_simple)
h2o_valid_simple &lt;- as.h2o(valid_simple)</code></pre>
<ul>
<li>Setup features</li>
</ul>
<pre class="r"><code>simple_features &lt;- setdiff(names(train_simple), c(&quot;id&quot;, target))
simple_features</code></pre>
<pre class="r"><code>complex_features &lt;- setdiff(names(train_complex), c(&quot;id&quot;, target))
complex_features</code></pre>
</div>
<div id="automl" class="section level3">
<h3>AutoML</h3>
<ul>
<li>Outline AutoMl</li>
</ul>
</div>
</div>
<div id="establishing-a-baseline" class="section level2">
<h2>Establishing a baseline</h2>
<ul>
<li>H2o AutoML on the clean data</li>
</ul>
<pre class="r"><code>CleanBaselineAutoML &lt;- h2o.automl(x = simple_features,
                                  y = target,
                                  training_frame = h2o_train_simple,
                                  leaderboard_frame = h2o_valid_simple,
                                  nfolds = 3,
                                  max_runtime_secs = tune_time)

CleanBaselineAutoML@leaderboard</code></pre>
<ul>
<li>Look at the model</li>
</ul>
<pre class="r"><code>clean_baseline_model &lt;- CleanBaselineAutoML@leader

h2o.performance(clean_baseline_model, valid = TRUE)</code></pre>
<ul>
<li>H2o AutoMl on the dirty data</li>
</ul>
<pre class="r"><code>BaselineAutoML &lt;- h2o.automl(x = complex_features,
                             y = target,
                             training_frame = h2o_train_complex,
                             leaderboard_frame = h2o_valid_complex,
                             nfolds = 3,
                             max_runtime_secs = tune_time)

BaselineAutoML@leaderboard

baseline_model &lt;- BaselineAutoML@leader

h2o.performance(baseline_model, valid = TRUE)</code></pre>
</div>
<div id="vtreat" class="section level2">
<h2><code>vtreat</code></h2>
<div id="what-is-it" class="section level3">
<h3>What is it</h3>
<ul>
<li>Outline of the package</li>
<li>Overview of what the package can do</li>
<li>Problems that the package can help with</li>
<li>List of new variables created and roll they play</li>
<li>Pointers to more info.</li>
</ul>
</div>
<div id="preparing-the-treatment" class="section level3">
<h3>Preparing the treatment</h3>
<pre class="r"><code>prep &lt;- mkCrossFrameCExperiment(dframe = train_complex,
                                varlist = complex_features,
                                outcomename = target,
                                outcometarget = &quot;bad&quot;,
                                rareCount = 5,
                                ncross = 5,
           scale = TRUE
)

prep</code></pre>
<ul>
<li>Explore evidence levels for predictors and consider pruning.</li>
</ul>
<pre class="r"><code>treatments &lt;- prep$treatments

treatments$scoreFrame[,c(&#39;varName&#39;,&#39;sig&#39;)] %&gt;% 
  arrange(sig)</code></pre>
<ul>
<li>Prune to get new features (think about this carefully)</li>
</ul>
<pre class="r"><code>all_vars &lt;- treatments$scoreFrame$varName

pruneSig &lt;- 1/(ncol(train_complex) - 1)

pruned_vars &lt;- treatments$scoreFrame$varName[treatments$scoreFrame$sig &lt;= pruneSig]

pruned_vars</code></pre>
<ul>
<li>Prepare validation data</li>
</ul>
<pre class="r"><code>vtreat_valid &lt;- prepare(treatments,
                        valid_complex,
                        varRestriction = all_vars) %&gt;% 
  as.h2o
vtreat_valid_pruned &lt;- prepare(treatments,
                               valid_complex,
                               varRestriction = pruned_vars) %&gt;% 
  as.h2o</code></pre>
</div>
<div id="automl-comparision" class="section level3">
<h3>AutoML comparision</h3>
<ul>
<li>AutoMl on all <code>vtreat</code> variables</li>
</ul>
<pre class="r"><code>VreatAutoML &lt;- h2o.automl(x = all_vars,
                          y = target,
                          training_frame = prep$crossFrame %&gt;% as.h2o,
                          leaderboard_frame = vtreat_valid,
                          nfolds = 3,
                          max_runtime_secs = tune_time)

VreatAutoML@leaderboard

vtreat_model &lt;- VreatAutoML@leader

h2o.performance(vtreat_model , valid = TRUE)</code></pre>
<ul>
<li>AutoML on pruned model</li>
</ul>
<pre class="r"><code>PrunedVreatAutoML &lt;- h2o.automl(x = pruned_vars,
                             y = target,
                             training_frame = prep$crossFrame %&gt;% as.h2o,
                             leaderboard_frame = vtreat_valid_pruned,
                             nfolds = 3,
                             max_runtime_secs = tune_time)

PrunedVreatAutoML@leaderboard

pruned_vtreat_model &lt;- PrunedVreatAutoML@leader

h2o.performance(pruned_vtreat_model , valid = TRUE)</code></pre>
</div>
</div>
<div id="recipes" class="section level2">
<h2><code>recipes</code></h2>
<div id="what-is-it-1" class="section level3">
<h3>What is it</h3>
</div>
<div id="preparing-the-data" class="section level3">
<h3>Preparing the data</h3>
<pre class="r"><code>train_complex</code></pre>
</div>
<div id="automl-comparision-1" class="section level3">
<h3>AutoML Comparision</h3>
</div>
</div>
<div id="model-comparsion" class="section level2">
<h2>Model Comparsion</h2>
<div id="on-test-data" class="section level3">
<h3>On test data</h3>
<ul>
<li>compare predictive performance</li>
</ul>
</div>
</div>
<div id="using-iml" class="section level2">
<h2>Using <code>iml</code></h2>
<ul>
<li><code>iml</code> package</li>
<li>compare model feature performance</li>
<li>compare interactions</li>
</ul>
</div>
<div id="summary-and-wrap-up" class="section level2">
<h2>Summary and Wrap-up</h2>
<pre class="r"><code>storyboard &lt;- NULL

ggsave(&quot;../../static/img/getTBinR/tb-country-anomalies.png&quot;,
       storyboard, width = 20, height = 16, dpi = 330)

storyboard</code></pre>
</div>
