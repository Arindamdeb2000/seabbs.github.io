---
title: "Benchmarking an Rstats Workstation on Realistic Workloads - using xgboost via h2o"
author: 'null'
date: '2019-01-26'
description: ""
slug: benchmarking-workstation
draft: yes 
tags: ["benchmark", "cpu", "gpu", "data science", "xgboost", "h2o", "workstation"]
categories: ["R"]
twitterImg: ""
---



<div id="why" class="section level2">
<h2>Why?</h2>
<p>I recently <a href="https://www.samabbott.co.uk/post/building-an-rstats-workstation/">built out a new workstation</a> to give me some local compute for rstats data science work loads. Now that I have local access to both a CPU with a large number of cores (Threadripper 1950X with 16 cores) and a moderately powerful GPU (Nvidia RTX 2070) I’m interested in knowing when it is best to use CPU vs. GPU for some of the tasks that I commonly do. The first of these is fitting <code>xgboost</code> models for predictive tasks, this makes sense as a first problem to explore as in my experiance (and in the experiance of the wider community) <code>xgboost</code> generally provides the best performance on tabular I.D.D data (although more recently Light GBM has been performing well - this is not yet integrated into my common tool set so I have not made a great deal of use of it). I am also interested in exploring whether or not simultaneous multithreading (i.e Hyper-threading for Intel CPUs) gives any performance boost over using only phyiscal cores for these workloads (I couldn’t find much on this online for AMD CPUs). If this proves not to be the case disabling this gives me a greater scope for overclocking my new workstation’s CPU.</p>
</div>
<div id="aims" class="section level2">
<h2>Aims</h2>
<ul>
<li><p>Understand when the CPU of my new workstation is optimal versus when the GPU is optimal when using <code>xgboost</code> via <code>h2o</code>.</p></li>
<li><p>Explore whether it makes sense to use virtual cores versus physical cores. If virtual cores add little to no additional performance then it may be attractive to disable this feature as this will enable further overclocking.</p></li>
<li><p>Explore how these features scale across different data sizes and tree ensemble sizes.</p></li>
</ul>
</div>
<div id="developing-a-testing-function" class="section level2">
<h2>Developing a testing function</h2>
<p>As a first step we outline a hyper-parameter grid to search over and specify the parameters of the grid search. We turn off early stopping (which is not something that we would do in a real use case) to allow control over the exact number of trees being trained.</p>
<pre class="r"><code>## Search criteria
search_crit &lt;- list(strategy = &quot;RandomDiscrete&quot;, 
                    max_models = 10, stopping_rounds = 10)

hyper_params &lt;- list(
  learn_rate = c(0.1, 0.3, 0.5),
  sample_rate = c(0.6, 0.8, 1),
  col_sample_rate = c(0.6, 0.8, 1),
  max_depth = c(1, 5, 10),
  min_rows = c(1, 2, 5),
  reg_lambda = c(0, 0.001),
  reg_alpha = c(0, 0.001)
)

spec_grid &lt;- partial(h2o.grid,
                     algorithm = &quot;xgboost&quot;,
                     nfolds = 5,
                     seed = 2344232,
                     stopping_rounds = 0,
                     search_criteria = search_crit,
                     hyper_params = hyper_params)</code></pre>
<p>Next we develop a function to fit and time a single grid as specified on a subsample of the rows and columns supplied on a given number of CPU cores and potentially with a GPU backend.</p>
<pre class="r"><code>benchmark_grid &lt;- function(df,
                           target,
                           grid = NULL,
                           cores = NULL, 
                           gpu = FALSE,
                           rowsample = 1e3,
                           trees = NULL,
                           colsample = 1,
                           ram = 28) {
  
## Initialise the h2o cluster with the desired core number
  h2o.init(min_mem_size = paste0(ram, &quot;g&quot;),
           nthreads = cores)
  h2o.no_progress()

## Sample columns (up/down sampling)
  df &lt;- df[target] %&gt;% 
    bind_cols(df %&gt;%
                select(-contains(target)) %&gt;% 
                {.[, sample(1:ncol(.), colsample, replace = TRUE)]})
  
## Specify the training data and set 
  h2o_train &lt;- sample_n(df, rowsample, replace = TRUE) %&gt;% 
    as.h2o

## Specify the features
  features &lt;- setdiff(colnames(df), target)
  
## Start the timer
tic(paste0(&quot;Trained a &quot;,
           &quot;grid of 10 Xgboost &quot;, 
           &quot;models with &quot;, cores, &quot; cores&quot;, 
            ifelse(gpu, &quot; using the GPU backend&quot;, &quot;&quot;),
            &quot; on a subsample of &quot;,
            rowsample, 
            &quot; rows and &quot;,
            colsample, 
           &quot; features with &quot;,
           trees, 
           &quot; trees.&quot;))

  if(object.size(df) &gt; ((ram * 1000^3)/ cores)) {
    message(&quot;Data size is to big to fit into RAM in this configuration&quot;)
    
    model_fit &lt;- FALSE
  }else{
    ## Train the models
  trained_grid &lt;- grid(y = target,
                       x = features,
                       training_frame = h2o_train,
                       backend = ifelse(gpu, &quot;gpu&quot;, &quot;cpu&quot;)) 
  
  model_fit &lt;- TRUE
  }


  
time &lt;- toc()

time$fit &lt;- model_fit

h2o.shutdown(prompt = FALSE)

Sys.sleep(3)
return(time)
}</code></pre>
</div>
<div id="sourcing-test-data" class="section level2">
<h2>Sourcing Test Data</h2>
<p>We use credit data from the <code>recipes</code> package as an example of a real world dataset. A binary outcome has been chosen as this reflects much of the modelling I do day to day (usually loan defaults).</p>
<pre class="r"><code>credit_data &lt;- recipes::credit_data %&gt;% 
  as_tibble

skim(credit_data) %&gt;% 
  skimr::kable()</code></pre>
<p>Skim summary statistics<br />
n obs: 4454<br />
n variables: 14</p>
<p>Variable type: factor</p>
<table>
<thead>
<tr class="header">
<th align="center">variable</th>
<th align="center">missing</th>
<th align="center">complete</th>
<th align="center">n</th>
<th align="center">n_unique</th>
<th align="center">top_counts</th>
<th align="center">ordered</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Home</td>
<td align="center">6</td>
<td align="center">4448</td>
<td align="center">4454</td>
<td align="center">6</td>
<td align="center">own: 2107, ren: 973, par: 783, oth: 319</td>
<td align="center">FALSE</td>
</tr>
<tr class="even">
<td align="center">Job</td>
<td align="center">2</td>
<td align="center">4452</td>
<td align="center">4454</td>
<td align="center">4</td>
<td align="center">fix: 2805, fre: 1024, par: 452, oth: 171</td>
<td align="center">FALSE</td>
</tr>
<tr class="odd">
<td align="center">Marital</td>
<td align="center">1</td>
<td align="center">4453</td>
<td align="center">4454</td>
<td align="center">5</td>
<td align="center">mar: 3241, sin: 977, sep: 130, wid: 67</td>
<td align="center">FALSE</td>
</tr>
<tr class="even">
<td align="center">Records</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">2</td>
<td align="center">no: 3681, yes: 773, NA: 0</td>
<td align="center">FALSE</td>
</tr>
<tr class="odd">
<td align="center">Status</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">2</td>
<td align="center">goo: 3200, bad: 1254, NA: 0</td>
<td align="center">FALSE</td>
</tr>
</tbody>
</table>
<p>Variable type: integer</p>
<table>
<thead>
<tr class="header">
<th align="center">variable</th>
<th align="center">missing</th>
<th align="center">complete</th>
<th align="center">n</th>
<th align="center">mean</th>
<th align="center">sd</th>
<th align="center">p0</th>
<th align="center">p25</th>
<th align="center">p50</th>
<th align="center">p75</th>
<th align="center">p100</th>
<th align="center">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Age</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">37.08</td>
<td align="center">10.98</td>
<td align="center">18</td>
<td align="center">28</td>
<td align="center">36</td>
<td align="center">45</td>
<td align="center">68</td>
<td align="center">▅▇▇▇▅▃▂▁</td>
</tr>
<tr class="even">
<td align="center">Amount</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">1038.92</td>
<td align="center">474.55</td>
<td align="center">100</td>
<td align="center">700</td>
<td align="center">1000</td>
<td align="center">1300</td>
<td align="center">5000</td>
<td align="center">▅▇▃▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="center">Assets</td>
<td align="center">47</td>
<td align="center">4407</td>
<td align="center">4454</td>
<td align="center">5403.98</td>
<td align="center">11574.42</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">3000</td>
<td align="center">6000</td>
<td align="center">3e+05</td>
<td align="center">▇▁▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td align="center">Debt</td>
<td align="center">18</td>
<td align="center">4436</td>
<td align="center">4454</td>
<td align="center">343.03</td>
<td align="center">1245.99</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">30000</td>
<td align="center">▇▁▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="center">Expenses</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">55.57</td>
<td align="center">19.52</td>
<td align="center">35</td>
<td align="center">35</td>
<td align="center">51</td>
<td align="center">72</td>
<td align="center">180</td>
<td align="center">▇▃▃▁▁▁▁▁</td>
</tr>
<tr class="even">
<td align="center">Income</td>
<td align="center">381</td>
<td align="center">4073</td>
<td align="center">4454</td>
<td align="center">141.69</td>
<td align="center">80.75</td>
<td align="center">6</td>
<td align="center">90</td>
<td align="center">125</td>
<td align="center">170</td>
<td align="center">959</td>
<td align="center">▇▆▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="center">Price</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">1462.78</td>
<td align="center">628.13</td>
<td align="center">105</td>
<td align="center">1117.25</td>
<td align="center">1400</td>
<td align="center">1691.5</td>
<td align="center">11140</td>
<td align="center">▇▆▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td align="center">Seniority</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">7.99</td>
<td align="center">8.17</td>
<td align="center">0</td>
<td align="center">2</td>
<td align="center">5</td>
<td align="center">12</td>
<td align="center">48</td>
<td align="center">▇▃▂▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="center">Time</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">46.44</td>
<td align="center">14.66</td>
<td align="center">6</td>
<td align="center">36</td>
<td align="center">48</td>
<td align="center">60</td>
<td align="center">72</td>
<td align="center">▁▁▂▃▁▃▇▁</td>
</tr>
</tbody>
</table>
<p>This dataset has been cleaned and contains a limited number, of presumably fairly predictive, variables. To make this a more realistic test we introduce additional numeric and categorical noise variables as well as adding missing data and duplicating our original features.</p>
<ul>
<li>Add numeric and categorical noise features. Categorical features are randomly sampled and assigned 10, 50, 100, 250, 500 and 1000 levels, whilst numeric features are normally distributed with or without a log transform.</li>
</ul>
<pre class="r"><code>## Set up categorical variable generation
get_cat_noise_var &lt;- function(levels = NULL, samples) {
  sample(paste(&#39;level&#39;,1:levels,sep=&#39;&#39;), samples, replace=TRUE)
}

## Generate categorical variable with differing lengths (10, 100, 1000)
cat_noise_var &lt;- map(c(10, 50, 100, 250, 500, 1000), ~ rep(., 5)) %&gt;% 
  flatten %&gt;% 
  map_dfc(~get_cat_noise_var(., nrow(credit_data))) %&gt;% 
  set_names(paste0(&quot;CatNoise_&quot;, 1:30)) %&gt;% 
  map_dfc(factor)

## Set up numeric variable generation. Normal with random mean and standard deviation (or log normal)
get_num_noise_var &lt;- function(noise = 0.1, samples, log_shift = FALSE) {
  mean &lt;- runif(1, -1e3, 1e3)
  x &lt;- rnorm(samples, mean, abs(mean) * noise)
  
  if (log_shift) { 
   x &lt;- log(abs(x + 1))
  }
  
  return(x)
}

## Generate numeric variables with varying amounts of noise and transforming using log
gen_numeric_var &lt;- function(df, log_shift) {
  map(c(0.1, 0.2, 0.4), ~ rep(., 5)) %&gt;% 
  flatten %&gt;% 
  map_dfc( ~ get_num_noise_var(., nrow(df), log_shift))
}

num_noise_var &lt;- gen_numeric_var(credit_data, log_shift = FALSE) %&gt;% 
  bind_cols(gen_numeric_var(credit_data, log_shift = TRUE)) %&gt;% 
    set_names(paste0(&quot;NumNoise_&quot;, 1:30))
  

## Bind together and summarise
noise_var &lt;- cat_noise_var %&gt;% 
  bind_cols(num_noise_var)</code></pre>
<ul>
<li>Add duplicate informative features.</li>
</ul>
<pre class="r"><code>credit_data &lt;- credit_data %&gt;% 
  select(Status) %&gt;% 
  bind_cols(credit_data %&gt;% 
              select(-Status) %&gt;% 
              {bind_cols(., .)} %&gt;% 
              {bind_cols(., .)})</code></pre>
<p>Add some missingness to the data and replace the home owners <code>&quot;other&quot;</code> category with 1000 random levels. Adding random noise levels to the home owners variable means that some information is now encoded in a very noisy feature - providing more of a challenge for the <code>xgboost</code> model.</p>
<pre class="r"><code>add_miss &lt;- function(x = NULL, max_miss = NULL) {
  miss_scale &lt;- runif(1, 0, max_miss)
  
  x &lt;- replace(x, runif(length(x), 0, 1) &lt;= miss_scale, NA)
}



complex_credit_data &lt;- credit_data %&gt;% 
  bind_cols(noise_var) %&gt;% 
  mutate_at(.vars = vars(everything(), - Status), ~ add_miss(., 0.2)) %&gt;% 
  mutate(
    Home = case_when(Home %in% &quot;other&quot; ~ as.character(CatNoise_30),
                          TRUE ~ as.character(Home)) %&gt;% 
           factor)


complex_credit_data</code></pre>
<pre><code>## # A tibble: 4,454 x 113
##    Status Seniority Home   Time   Age Marital Records Job   Expenses Income
##    &lt;fct&gt;      &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt;   &lt;fct&gt;   &lt;fct&gt;    &lt;int&gt;  &lt;int&gt;
##  1 good          NA &lt;NA&gt;     60    30 married &lt;NA&gt;    free…       73    129
##  2 good          17 rent     60    58 widow   no      &lt;NA&gt;        48    131
##  3 bad           NA owner    36    46 married yes     free…       90    200
##  4 good           0 rent     60    24 single  &lt;NA&gt;    fixed       63    182
##  5 good           0 rent     36    26 single  no      fixed       46    107
##  6 good           1 owner    NA    36 married no      fixed       75    214
##  7 good          NA &lt;NA&gt;     60    44 &lt;NA&gt;    no      fixed       75    125
##  8 good           9 pare…    12    27 &lt;NA&gt;    &lt;NA&gt;    fixed       35     80
##  9 good           0 owner    60    32 &lt;NA&gt;    no      free…       90    107
## 10 bad            0 pare…    48    41 married no      part…       90     80
## # ... with 4,444 more rows, and 103 more variables: Assets &lt;int&gt;,
## #   Debt &lt;int&gt;, Amount &lt;int&gt;, Price &lt;int&gt;, Seniority1 &lt;int&gt;, Home1 &lt;fct&gt;,
## #   Time1 &lt;int&gt;, Age1 &lt;int&gt;, Marital1 &lt;fct&gt;, Records1 &lt;fct&gt;, Job1 &lt;fct&gt;,
## #   Expenses1 &lt;int&gt;, Income1 &lt;int&gt;, Assets1 &lt;int&gt;, Debt1 &lt;int&gt;,
## #   Amount1 &lt;int&gt;, Price1 &lt;int&gt;, Seniority2 &lt;int&gt;, Home2 &lt;fct&gt;,
## #   Time2 &lt;int&gt;, Age2 &lt;int&gt;, Marital2 &lt;fct&gt;, Records2 &lt;fct&gt;, Job2 &lt;fct&gt;,
## #   Expenses2 &lt;int&gt;, Income2 &lt;int&gt;, Assets2 &lt;int&gt;, Debt2 &lt;int&gt;,
## #   Amount2 &lt;int&gt;, Price2 &lt;int&gt;, Seniority11 &lt;int&gt;, Home11 &lt;fct&gt;,
## #   Time11 &lt;int&gt;, Age11 &lt;int&gt;, Marital11 &lt;fct&gt;, Records11 &lt;fct&gt;,
## #   Job11 &lt;fct&gt;, Expenses11 &lt;int&gt;, Income11 &lt;int&gt;, Assets11 &lt;int&gt;,
## #   Debt11 &lt;int&gt;, Amount11 &lt;int&gt;, Price11 &lt;int&gt;, CatNoise_1 &lt;fct&gt;,
## #   CatNoise_2 &lt;fct&gt;, CatNoise_3 &lt;fct&gt;, CatNoise_4 &lt;fct&gt;,
## #   CatNoise_5 &lt;fct&gt;, CatNoise_6 &lt;fct&gt;, CatNoise_7 &lt;fct&gt;,
## #   CatNoise_8 &lt;fct&gt;, CatNoise_9 &lt;fct&gt;, CatNoise_10 &lt;fct&gt;,
## #   CatNoise_11 &lt;fct&gt;, CatNoise_12 &lt;fct&gt;, CatNoise_13 &lt;fct&gt;,
## #   CatNoise_14 &lt;fct&gt;, CatNoise_15 &lt;fct&gt;, CatNoise_16 &lt;fct&gt;,
## #   CatNoise_17 &lt;fct&gt;, CatNoise_18 &lt;fct&gt;, CatNoise_19 &lt;fct&gt;,
## #   CatNoise_20 &lt;fct&gt;, CatNoise_21 &lt;fct&gt;, CatNoise_22 &lt;fct&gt;,
## #   CatNoise_23 &lt;fct&gt;, CatNoise_24 &lt;fct&gt;, CatNoise_25 &lt;fct&gt;,
## #   CatNoise_26 &lt;fct&gt;, CatNoise_27 &lt;fct&gt;, CatNoise_28 &lt;fct&gt;,
## #   CatNoise_29 &lt;fct&gt;, CatNoise_30 &lt;fct&gt;, NumNoise_1 &lt;dbl&gt;,
## #   NumNoise_2 &lt;dbl&gt;, NumNoise_3 &lt;dbl&gt;, NumNoise_4 &lt;dbl&gt;,
## #   NumNoise_5 &lt;dbl&gt;, NumNoise_6 &lt;dbl&gt;, NumNoise_7 &lt;dbl&gt;,
## #   NumNoise_8 &lt;dbl&gt;, NumNoise_9 &lt;dbl&gt;, NumNoise_10 &lt;dbl&gt;,
## #   NumNoise_11 &lt;dbl&gt;, NumNoise_12 &lt;dbl&gt;, NumNoise_13 &lt;dbl&gt;,
## #   NumNoise_14 &lt;dbl&gt;, NumNoise_15 &lt;dbl&gt;, NumNoise_16 &lt;dbl&gt;,
## #   NumNoise_17 &lt;dbl&gt;, NumNoise_18 &lt;dbl&gt;, NumNoise_19 &lt;dbl&gt;,
## #   NumNoise_20 &lt;dbl&gt;, NumNoise_21 &lt;dbl&gt;, NumNoise_22 &lt;dbl&gt;,
## #   NumNoise_23 &lt;dbl&gt;, NumNoise_24 &lt;dbl&gt;, NumNoise_25 &lt;dbl&gt;,
## #   NumNoise_26 &lt;dbl&gt;, NumNoise_27 &lt;dbl&gt;, …</code></pre>
</div>
<div id="testing-on-for-a-single-iteration" class="section level2">
<h2>Testing on for a Single Iteration</h2>
<p>To check that everything is working as expected we test on a single iteration with 31 cores, no GPU, 100,000 samples, 20 features and 1000 trees.</p>
<pre class="r"><code>grid_test &lt;- benchmark_grid(complex_credit_data,
                            &quot;Status&quot;,
                            grid = spec_grid,
                            cores = 31, 
                            gpu = FALSE,
                            rowsample = 1e4,
                            trees = 50,
                            colsample = 20)</code></pre>
<pre><code>## 
## H2O is not running yet, starting it now...
## 
## Note:  In case of errors look at the following log files:
##     /tmp/RtmpSE3NgR/h2o_seabbs_started_from_r.out
##     /tmp/RtmpSE3NgR/h2o_seabbs_started_from_r.err
## 
## 
## Starting H2O JVM and connecting: . Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         1 seconds 101 milliseconds 
##     H2O cluster timezone:       Etc/UTC 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.23.0.4553 
##     H2O cluster version age:    2 days  
##     H2O cluster name:           H2O_started_from_R_seabbs_esw572 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   26.83 GB 
##     H2O cluster total cores:    32 
##     H2O cluster allowed cores:  31 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
##     R Version:                  R version 3.5.2 (2018-12-20) 
## 
## Trained a grid of 10 Xgboost models with 31 cores on a subsample of 10000 rows and 20 features with 50 trees.: 59.669 sec elapsed</code></pre>
<pre class="r"><code>grid_test</code></pre>
<pre><code>## $tic
## elapsed 
##   8.494 
## 
## $toc
## elapsed 
##  68.163 
## 
## $msg
## [1] &quot;Trained a grid of 10 Xgboost models with 31 cores on a subsample of 10000 rows and 20 features with 50 trees.&quot;
## 
## $fit
## [1] TRUE</code></pre>
<p>We see that the settings above give a runtime of around a minute but using the <code>htop</code> tool we see that resource use is not stable over time. This may indicate that <code>h2o</code> is not using all the supplied cores effectively/efficiently for this data size, with these settings etc.</p>
<div class="figure">
<img src="/img/2019-01-20-benchmarking-workstation-xgboost/load-example.gif" alt="Load according to htop whilst running the test grid." />
<p class="caption">Load according to <code>htop</code> whilst running the test grid.</p>
</div>
</div>
<div id="enabling-gpu-support" class="section level2">
<h2>Enabling GPU support</h2>
<p>Unlike using CPUs for <code>xgboost</code>, enabling GPU support requires some extra steps (and lots of faff). As I have a Nvidia GPU I need to install CUDA on my local machine (see <a href="https://www.samabbott.co.uk/post/building-an-rstats-workstation/">here</a> for details), CUDA 8.0 (or higher) into the Docker container that this analysis is running in (see here for the shell script) and run the Docker container using the <a href="https://github.com/NVIDIA/nvidia-docker">Nvidia Docker runtime</a>. To check everything is working we can use the <code>nvidia-smi</code> tool.</p>
<pre class="bash"><code>nvidia-smi</code></pre>
</div>
<div id="iterating-across-a-grid" class="section level2">
<h2>Iterating Across a Grid</h2>
<p>We can now iterate across a benchmarking grid. Here we combine all combinations of data sizes from 10,000 to 100,000 rows and from 10 to 1000 columns, tress numbers from 10 to 10,000 and compute availability (here 4, 16, and 32 cores + GPU). Something that I have now implemented here but that would reduce the noise in the final results is running each benchmark multiple times. As you will see below this is not feasible for a weekend blog post!</p>
<ul>
<li>Grid set-up</li>
</ul>
<pre class="r"><code>benchmark_input &lt;- expand.grid(
  cores = c(4, 16, 32),
  rowsample = c(1e3, 1e4, 2.5e4, 5e4, 7.5e4, 1e5),
  colsample = c(10, 100, 1000),
  trees = c(10, 100, 1000, 10000),
  gpu = c(FALSE),
  rep = 1
) %&gt;% 
  as_tibble() %&gt;% 
  mutate(size = rowsample * colsample * trees) %&gt;% 
  arrange(desc(size), cores)

benchmark_input</code></pre>
<pre><code>## # A tibble: 216 x 7
##    cores rowsample colsample trees gpu     rep          size
##    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt;         &lt;dbl&gt;
##  1     4    100000      1000 10000 FALSE     1 1000000000000
##  2    16    100000      1000 10000 FALSE     1 1000000000000
##  3    32    100000      1000 10000 FALSE     1 1000000000000
##  4     4     75000      1000 10000 FALSE     1  750000000000
##  5    16     75000      1000 10000 FALSE     1  750000000000
##  6    32     75000      1000 10000 FALSE     1  750000000000
##  7     4     50000      1000 10000 FALSE     1  500000000000
##  8    16     50000      1000 10000 FALSE     1  500000000000
##  9    32     50000      1000 10000 FALSE     1  500000000000
## 10     4     25000      1000 10000 FALSE     1  250000000000
## # ... with 206 more rows</code></pre>
<ul>
<li>Run benchmark</li>
</ul>
<pre class="r"><code>## Cached manually to avoid rerunning on knit.
if (!file.exists(&quot;../../static/data/workstation-benchmark/xgboost.rds&quot;)) {
  benchmark_output &lt;- benchmark_input %&gt;% 
  rowwise() %&gt;% 
  mutate(bench = list(as_tibble(benchmark_grid(complex_credit_data,
                                       &quot;Status&quot;,
                                        grid = spec_grid,
                                        cores = cores, 
                                        gpu = gpu,
                                        rowsample = rowsample,
                                        trees = trees,
                                        colsample = colsample)))) %&gt;% 
  unnest(bench) %&gt;%
  select(-msg) %&gt;% 
  mutate(duration = toc - tic) %&gt;% 
  filter(fit)
  
  saveRDS(benchmark_output, &quot;../../static/data/workstation-benchmark/xgboost.rds&quot;)
}else{
  benchmark_output &lt;- readRDS( &quot;../../static/data/workstation-benchmark/xgboost.rds&quot;)
}

benchmark_output</code></pre>
<pre><code>## # A tibble: 216 x 11
##    cores rowsample colsample trees gpu     rep    size    tic    toc fit  
##    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;lgl&gt;
##  1     4    100000      1000 10000 FALSE     1 1.00e12   332.  5515. TRUE 
##  2    16    100000      1000 10000 FALSE     1 1.00e12  5582.  7141. TRUE 
##  3    32    100000      1000 10000 FALSE     1 1.00e12  7213.  8844. TRUE 
##  4     4     75000      1000 10000 FALSE     1 7.50e11  8899. 11925. TRUE 
##  5    16     75000      1000 10000 FALSE     1 7.50e11 11978. 13291. TRUE 
##  6    32     75000      1000 10000 FALSE     1 7.50e11 13349. 14974. TRUE 
##  7     4     50000      1000 10000 FALSE     1 5.00e11 15013. 18061. TRUE 
##  8    16     50000      1000 10000 FALSE     1 5.00e11 18099. 19046. TRUE 
##  9    32     50000      1000 10000 FALSE     1 5.00e11 19090. 20008. TRUE 
## 10     4     25000      1000 10000 FALSE     1 2.50e11 20032. 21311. TRUE 
## # ... with 206 more rows, and 1 more variable: duration &lt;dbl&gt;</code></pre>
</div>
<div id="benchmarking-results" class="section level2">
<h2>Benchmarking Results</h2>
<p>First we plot the actual duration for each grid, split out by compute amount, row numbers, column numbers and tree numbers. This gives us a good impression of the real world impact of additional compute availability.</p>
<pre class="r"><code>benchmark_output %&gt;% 
  group_by(rowsample, colsample, trees) %&gt;% 
  mutate(duration = duration / 60) %&gt;% 
  mutate(Compute = paste0(cores, &quot; Threadripper 1950X CPU cores&quot;)) %&gt;% 
  ggplot(aes(rowsample, duration, col = Compute, group = Compute)) +
  geom_point() +
  geom_line() + 
  facet_grid(colsample ~ trees, scales = &quot;free_y&quot;) +
  theme_minimal() +
  theme(legend.position = &quot;top&quot;, axis.text.x = element_text(angle = 90,hjust = 1)) +
  scale_x_continuous(labels = scales::comma) + 
  scale_color_viridis_d(begin = 0.2, end = 0.8) +
  labs(x = &quot;Rows&quot;,
       y = &quot;Duration (minutes)&quot;,
       caption = &quot;Number of Trees ~ Number of Features&quot;)</code></pre>
<p><img src="/post/2019-01-26-benchmarking-workstation-xgboost_files/figure-html/unnamed-chunk-11-1.png" width="3200" /></p>
<p>Another way of looking at the benchmarking returns is to plot the percentage improvement from a given compute amount over the longest duration for that number of rows.</p>
<pre class="r"><code>benchmark_output %&gt;% 
  group_by(rowsample, colsample, trees) %&gt;% 
  mutate(duration = (max(duration) - duration) / max(duration)) %&gt;% 
  arrange(cores) %&gt;% 
  mutate(Compute = cores %&gt;% 
           paste0(&quot; Threadripper 1950X CPU cores&quot;) %&gt;% 
           factor) %&gt;% 
  ggplot(aes(rowsample, duration, col = Compute, group = Compute)) +
  geom_point() +
  geom_line() + 
  facet_grid(colsample ~ trees, scales = &quot;free_y&quot;) +
  theme_minimal() +
  theme(legend.position = &quot;top&quot;, axis.text.x = element_text(angle=90,hjust=1)) +
  scale_y_continuous(labels = scales::percent) +
  scale_x_continuous(labels = scales::comma) + 
  scale_color_viridis_d(begin = 0.2, end = 0.8) +
  labs(x = &quot;Rows&quot;,
       y = &quot;Performance improvement over baseline (%)&quot;,
       caption = &quot;Number of Trees ~ Number of Features&quot;)</code></pre>
<p><img src="/post/2019-01-26-benchmarking-workstation-xgboost_files/figure-html/unnamed-chunk-12-1.png" width="3200" /></p>
</div>
