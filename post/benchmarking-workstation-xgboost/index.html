<!DOCTYPE html>
<html lang="en-uk">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.54.0" />
  <meta name="author" content="Sam Abbott">

  
  
  
  
    
      
    
  
  <meta name="description" content="Why? I recently built out a new workstation to give me some local compute for data science workloads. Now that I have local access to both a CPU with a large number of cores (Threadripper 1950X with 16 cores) and a moderately powerful GPU (Nvidia RTX 2070), I’m interested in knowing when it is best to use CPU vs. GPU for some of the tasks that I commonly do.">

  
  <link rel="alternate" hreflang="en-uk" href="http://www.samabbott.co.uk/post/benchmarking-workstation-xgboost/">

  


  

  
  
  <meta name="theme-color" content="#0095eb">
  
  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="../../styles.css">
  

  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-85604924-1', 'auto');
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  

  
  <link rel="alternate" href="http://www.samabbott.co.uk/index.xml" type="application/rss+xml" title="Sam Abbott">
  <link rel="feed" href="http://www.samabbott.co.uk/index.xml" type="application/rss+xml" title="Sam Abbott">
  

  <link rel="manifest" href="../../site.webmanifest">
  <link rel="icon" type="image/png" href="../../img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="../../img/icon-192.png">

  <link rel="canonical" href="http://www.samabbott.co.uk/post/benchmarking-workstation-xgboost/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@seabbs">
  <meta property="twitter:creator" content="@seabbs">
  
  <meta property="og:site_name" content="Sam Abbott">
  <meta property="og:url" content="http://www.samabbott.co.uk/post/benchmarking-workstation-xgboost/">
  <meta property="og:title" content="Benchmarking an Rstats workstation on realistic workloads - using xgboost via h2o | Sam Abbott">
  <meta property="og:description" content="Why? I recently built out a new workstation to give me some local compute for data science workloads. Now that I have local access to both a CPU with a large number of cores (Threadripper 1950X with 16 cores) and a moderately powerful GPU (Nvidia RTX 2070), I’m interested in knowing when it is best to use CPU vs. GPU for some of the tasks that I commonly do.">
  <meta property="og:locale" content="en-uk">
  
  <meta property="article:published_time" content="2019-02-03T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2019-02-03T00:00:00&#43;00:00">
  

  <!DOCTYPE html>


<title>Benchmarking an Rstats workstation on realistic workloads - using xgboost via h2o - Sam Abbott</title>
<meta property="og:title" content="Benchmarking an Rstats workstation on realistic workloads - using xgboost via h2o - Sam Abbott">
<meta property="og:type" content="article">

  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://raw.githubusercontent.com/seabbs/seabbs.github.io/sources/static/img/2019-01-20-benchmarking-workstation-xgboost/cover_img.png" >
  
  

<meta property="description" content="Benchmarking xgboost (via h2o) with CPU vs. GPU on a realistic data set using a cross-validated hyper-parameter search.">
<meta property="og:description" content="Benchmarking xgboost (via h2o) with CPU vs. GPU on a realistic data set using a cross-validated hyper-parameter search.">


<meta name="twitter:creator" content="">
<meta name="twitter:site" content="">

  <title>Benchmarking an Rstats workstation on realistic workloads - using xgboost via h2o | Sam Abbott</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="../../"><img src="../../img/logo.png" alt="Sam Abbott"></a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="../../#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="../../#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="../../#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="../../#talks">
            
            <span>Talks</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="../../#teaching">
            
            <span>Teaching</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="../../#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="../../#tags">
            
            <span>Tags</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="../../pdf/cv_sea.pdf">
            
            <span>CV</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Benchmarking an Rstats workstation on realistic workloads - using xgboost via h2o</h1>

    

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2019-02-03 00:00:00 &#43;0000 UTC" itemprop="datePublished dateModified">
      Sun, Feb 3, 2019
    </time>
  </span>
  <span itemscope itemprop="author publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Sam Abbott">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    18 min read
  </span>
  

  
  
  <span class="middot-divider"></span>
  <a href="http://www.samabbott.co.uk/post/benchmarking-workstation-xgboost/#disqus_thread"></a>
  

  
  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fa fa-folder"></i>
    
    <a href="../../categories/r">R</a
    >
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Benchmarking%20an%20Rstats%20workstation%20on%20realistic%20workloads%20-%20using%20xgboost%20via%20h2o&amp;url=http%3a%2f%2fwww.samabbott.co.uk%2fpost%2fbenchmarking-workstation-xgboost%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=http%3a%2f%2fwww.samabbott.co.uk%2fpost%2fbenchmarking-workstation-xgboost%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2fwww.samabbott.co.uk%2fpost%2fbenchmarking-workstation-xgboost%2f&amp;title=Benchmarking%20an%20Rstats%20workstation%20on%20realistic%20workloads%20-%20using%20xgboost%20via%20h2o"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=http%3a%2f%2fwww.samabbott.co.uk%2fpost%2fbenchmarking-workstation-xgboost%2f&amp;title=Benchmarking%20an%20Rstats%20workstation%20on%20realistic%20workloads%20-%20using%20xgboost%20via%20h2o"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Benchmarking%20an%20Rstats%20workstation%20on%20realistic%20workloads%20-%20using%20xgboost%20via%20h2o&amp;body=http%3a%2f%2fwww.samabbott.co.uk%2fpost%2fbenchmarking-workstation-xgboost%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


    <div class="article-style" itemprop="articleBody">
      


<div id="why" class="section level2">
<h2>Why?</h2>
<p>I recently <a href="https://www.samabbott.co.uk/post/building-an-rstats-workstation/">built out a new workstation</a> to give me some local compute for data science workloads. Now that I have local access to both a CPU with a large number of cores (Threadripper 1950X with 16 cores) and a moderately powerful GPU (Nvidia RTX 2070), I’m interested in knowing when it is best to use CPU vs. GPU for some of the tasks that I commonly do.</p>
<p>The first of these is fitting <code>xgboost</code> models for prediction. This makes sense as a first problem to explore as in my experience, and in the experience of the wider community, <code>xgboost</code> generally provides the best performance on tabular data - light GBM looks like it may be even better but the installation appears to be nightmarish - and predictive modelling is a fairly common use case. As I have recently been using the <a href="https://www.h2o.ai"><code>h2o</code> package</a> as my go-to tool, it makes sense for me to test <code>xgboost</code> via <code>h2o</code>.</p>
<p>I am also interested in exploring whether or not simultaneous multithreading (i.e Hyper-threading for Intel CPUs) gives any performance boost over using only physical cores for these workloads. I couldn’t find much on this online for AMD CPUs. My prior experience with Intel CPUs is that sticking to physical cores is the best option for nearly all serious compute. If this proves to be the case, disabling virtual core gives me a greater scope for overclocking!</p>
</div>
<div id="developing-a-testing-function" class="section level2">
<h2>Developing a testing function</h2>
<p>To make this a relatively real-world test, I am going to be comparing run times on a grid of cross-validated models (10 models, with 5 folds each). A nice benefit of this is that we can also see the average performance of a configuration across a variety of hyper-parameters. In the code below I have specified the grid and used the <code>purrr:partial</code> function to wrap everything up into a function. I’ve also turned off early stopping, which is not something that I would do in a real use case, to allow control over the exact number of trees being trained.</p>
<pre class="r"><code>## Search criteria
search_crit &lt;- list(strategy = &quot;RandomDiscrete&quot;, 
                    max_models = 10, stopping_rounds = 10)

hyper_params &lt;- list(
  learn_rate = c(0.1, 0.3, 0.5),
  sample_rate = c(0.6, 0.8, 1),
  col_sample_rate = c(0.6, 0.8, 1),
  max_depth = c(1, 5, 10),
  min_rows = c(1, 2, 5),
  reg_lambda = c(0, 0.001),
  reg_alpha = c(0, 0.001)
)

spec_grid &lt;- partial(h2o.grid,
                     algorithm = &quot;xgboost&quot;,
                     nfolds = 5,
                     seed = 2344232,
                     stopping_rounds = 0,
                     search_criteria = search_crit,
                     hyper_params = hyper_params)</code></pre>
<p>The next step is to develop a function to fit and time a single grid. This needs to be specified by a subsample of the rows and columns, on a given number of CPU cores, and potentially with a GPU backend.</p>
<pre class="r"><code>benchmark_grid &lt;- function(df,
                           target,
                           grid = NULL,
                           cores = NULL, 
                           gpu = FALSE,
                           rowsample = 1e3,
                           trees = NULL,
                           colsample = 1,
                           ram = 28) {
  
## Initialise the h2o cluster with the desired core number
  h2o.init(min_mem_size = paste0(ram, &quot;g&quot;),
           nthreads = cores)
  h2o.no_progress()

## Sample columns (up/down sampling)
  df &lt;- df[target] %&gt;% 
    bind_cols(df %&gt;%
                select(-contains(target)) %&gt;% 
                {.[, sample(1:ncol(.), colsample, replace = TRUE)]})
  
## Specify the training data and set 
  h2o_train &lt;- sample_n(df, rowsample, replace = TRUE) %&gt;% 
    as.h2o

## Specify the features
  features &lt;- setdiff(colnames(df), target)
  
## Start the timer
tic(paste0(&quot;Trained a &quot;,
           &quot;grid of 10 Xgboost &quot;, 
           &quot;models with &quot;, cores, &quot; cores&quot;, 
            ifelse(gpu, &quot; using the GPU backend&quot;, &quot;&quot;),
            &quot; on a subsample of &quot;,
            rowsample, 
            &quot; rows and &quot;,
            colsample, 
           &quot; features with &quot;,
           trees, 
           &quot; trees.&quot;))

  if(object.size(df) &gt; ((ram * 1000^3)/ cores)) {
    message(&quot;Data size is to big to fit into RAM in this configuration&quot;)
    
    model_fit &lt;- FALSE
  }else{
    ## Train the models
  trained_grid &lt;- grid(y = target,
                       x = features,
                       training_frame = h2o_train,
                       backend = ifelse(gpu, &quot;gpu&quot;, &quot;cpu&quot;)) 
  
  model_fit &lt;- TRUE
  }


  
time &lt;- toc()

time$fit &lt;- model_fit

h2o.shutdown(prompt = FALSE)

Sys.sleep(3)
return(time)
}</code></pre>
</div>
<div id="sourcing-test-data" class="section level2">
<h2>Sourcing test data</h2>
<p>As the base for my testing data, I am using credit data from the <code>recipes</code> package as an example of a real-world dataset. I went with a binary outcome as this reflects much of the modelling I have been doing day to day - usually loan defaults.</p>
<pre class="r"><code>credit_data &lt;- recipes::credit_data %&gt;% 
  as_tibble

skim(credit_data) %&gt;% 
  skimr::kable()</code></pre>
<p>Skim summary statistics<br />
n obs: 4454<br />
n variables: 14</p>
<p>Variable type: factor</p>
<table>
<thead>
<tr class="header">
<th align="center">variable</th>
<th align="center">missing</th>
<th align="center">complete</th>
<th align="center">n</th>
<th align="center">n_unique</th>
<th align="center">top_counts</th>
<th align="center">ordered</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Home</td>
<td align="center">6</td>
<td align="center">4448</td>
<td align="center">4454</td>
<td align="center">6</td>
<td align="center">own: 2107, ren: 973, par: 783, oth: 319</td>
<td align="center">FALSE</td>
</tr>
<tr class="even">
<td align="center">Job</td>
<td align="center">2</td>
<td align="center">4452</td>
<td align="center">4454</td>
<td align="center">4</td>
<td align="center">fix: 2805, fre: 1024, par: 452, oth: 171</td>
<td align="center">FALSE</td>
</tr>
<tr class="odd">
<td align="center">Marital</td>
<td align="center">1</td>
<td align="center">4453</td>
<td align="center">4454</td>
<td align="center">5</td>
<td align="center">mar: 3241, sin: 977, sep: 130, wid: 67</td>
<td align="center">FALSE</td>
</tr>
<tr class="even">
<td align="center">Records</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">2</td>
<td align="center">no: 3681, yes: 773, NA: 0</td>
<td align="center">FALSE</td>
</tr>
<tr class="odd">
<td align="center">Status</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">2</td>
<td align="center">goo: 3200, bad: 1254, NA: 0</td>
<td align="center">FALSE</td>
</tr>
</tbody>
</table>
<p>Variable type: integer</p>
<table>
<thead>
<tr class="header">
<th align="center">variable</th>
<th align="center">missing</th>
<th align="center">complete</th>
<th align="center">n</th>
<th align="center">mean</th>
<th align="center">sd</th>
<th align="center">p0</th>
<th align="center">p25</th>
<th align="center">p50</th>
<th align="center">p75</th>
<th align="center">p100</th>
<th align="center">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Age</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">37.08</td>
<td align="center">10.98</td>
<td align="center">18</td>
<td align="center">28</td>
<td align="center">36</td>
<td align="center">45</td>
<td align="center">68</td>
<td align="center">▅▇▇▇▅▃▂▁</td>
</tr>
<tr class="even">
<td align="center">Amount</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">1038.92</td>
<td align="center">474.55</td>
<td align="center">100</td>
<td align="center">700</td>
<td align="center">1000</td>
<td align="center">1300</td>
<td align="center">5000</td>
<td align="center">▅▇▃▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="center">Assets</td>
<td align="center">47</td>
<td align="center">4407</td>
<td align="center">4454</td>
<td align="center">5403.98</td>
<td align="center">11574.42</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">3000</td>
<td align="center">6000</td>
<td align="center">3e+05</td>
<td align="center">▇▁▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td align="center">Debt</td>
<td align="center">18</td>
<td align="center">4436</td>
<td align="center">4454</td>
<td align="center">343.03</td>
<td align="center">1245.99</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">30000</td>
<td align="center">▇▁▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="center">Expenses</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">55.57</td>
<td align="center">19.52</td>
<td align="center">35</td>
<td align="center">35</td>
<td align="center">51</td>
<td align="center">72</td>
<td align="center">180</td>
<td align="center">▇▃▃▁▁▁▁▁</td>
</tr>
<tr class="even">
<td align="center">Income</td>
<td align="center">381</td>
<td align="center">4073</td>
<td align="center">4454</td>
<td align="center">141.69</td>
<td align="center">80.75</td>
<td align="center">6</td>
<td align="center">90</td>
<td align="center">125</td>
<td align="center">170</td>
<td align="center">959</td>
<td align="center">▇▆▁▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="center">Price</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">1462.78</td>
<td align="center">628.13</td>
<td align="center">105</td>
<td align="center">1117.25</td>
<td align="center">1400</td>
<td align="center">1691.5</td>
<td align="center">11140</td>
<td align="center">▇▆▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td align="center">Seniority</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">7.99</td>
<td align="center">8.17</td>
<td align="center">0</td>
<td align="center">2</td>
<td align="center">5</td>
<td align="center">12</td>
<td align="center">48</td>
<td align="center">▇▃▂▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="center">Time</td>
<td align="center">0</td>
<td align="center">4454</td>
<td align="center">4454</td>
<td align="center">46.44</td>
<td align="center">14.66</td>
<td align="center">6</td>
<td align="center">36</td>
<td align="center">48</td>
<td align="center">60</td>
<td align="center">72</td>
<td align="center">▁▁▂▃▁▃▇▁</td>
</tr>
</tbody>
</table>
<p>This dataset has been cleaned and contains a limited number of, presumably fairly predictive, variables. To make this a more realistic test I’ve introduced additional numeric and categorical noise variables, as well as adding missing data and duplicating the original features - code below.</p>
<ul>
<li>Add numeric and categorical noise features. Categorical features are randomly sampled and assigned 10, 50, 100, 250, 500 and 1000 levels, whilst numeric features are normally distributed with or without a log transform.</li>
</ul>
<pre class="r"><code>## Set up categorical variable generation
get_cat_noise_var &lt;- function(levels = NULL, samples) {
  sample(paste(&#39;level&#39;,1:levels,sep=&#39;&#39;), samples, replace=TRUE)
}

## Generate categorical variable with differing lengths (10, 100, 1000)
cat_noise_var &lt;- map(c(10, 50, 100, 250, 500, 1000), ~ rep(., 5)) %&gt;% 
  flatten %&gt;% 
  map_dfc(~get_cat_noise_var(., nrow(credit_data))) %&gt;% 
  set_names(paste0(&quot;CatNoise_&quot;, 1:30)) %&gt;% 
  map_dfc(factor)

## Set up numeric variable generation. Normal with random mean and standard deviation (or log normal)
get_num_noise_var &lt;- function(noise = 0.1, samples, log_shift = FALSE) {
  mean &lt;- runif(1, -1e3, 1e3)
  x &lt;- rnorm(samples, mean, abs(mean) * noise)
  
  if (log_shift) { 
   x &lt;- log(abs(x + 1))
  }
  
  return(x)
}

## Generate numeric variables with varying amounts of noise and transforming using log
gen_numeric_var &lt;- function(df, log_shift) {
  map(c(0.1, 0.2, 0.4), ~ rep(., 5)) %&gt;% 
  flatten %&gt;% 
  map_dfc( ~ get_num_noise_var(., nrow(df), log_shift))
}

num_noise_var &lt;- gen_numeric_var(credit_data, log_shift = FALSE) %&gt;% 
  bind_cols(gen_numeric_var(credit_data, log_shift = TRUE)) %&gt;% 
    set_names(paste0(&quot;NumNoise_&quot;, 1:30))
  

## Bind together and summarise
noise_var &lt;- cat_noise_var %&gt;% 
  bind_cols(num_noise_var)</code></pre>
<ul>
<li>Add duplicate informative features.</li>
</ul>
<pre class="r"><code>credit_data &lt;- credit_data %&gt;% 
  select(Status) %&gt;% 
  bind_cols(credit_data %&gt;% 
              select(-Status) %&gt;% 
              {bind_cols(., .)} %&gt;% 
              {bind_cols(., .)})</code></pre>
<ul>
<li>Add some missingness to the data and replace the homeowners <code>&quot;other&quot;</code> category with 1000 random levels. Adding random noise levels to the homeowners variable means that some information is now encoded in a very noisy feature, providing more of a challenge for the <code>xgboost</code> model.</li>
</ul>
<pre class="r"><code>add_miss &lt;- function(x = NULL, max_miss = NULL) {
  miss_scale &lt;- runif(1, 0, max_miss)
  
  x &lt;- replace(x, runif(length(x), 0, 1) &lt;= miss_scale, NA)
}



complex_credit_data &lt;- credit_data %&gt;% 
  bind_cols(noise_var) %&gt;% 
  mutate_at(.vars = vars(everything(), - Status), ~ add_miss(., 0.2)) %&gt;% 
  mutate(
    Home = case_when(Home %in% &quot;other&quot; ~ as.character(CatNoise_30),
                          TRUE ~ as.character(Home)) %&gt;% 
           factor)


complex_credit_data</code></pre>
<pre><code>## # A tibble: 4,454 x 113
##    Status Seniority Home   Time   Age Marital Records Job   Expenses Income
##    &lt;fct&gt;      &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt;   &lt;fct&gt;   &lt;fct&gt;    &lt;int&gt;  &lt;int&gt;
##  1 good           9 rent     60    30 &lt;NA&gt;    no      free…       73    129
##  2 good          17 rent     60    58 widow   no      &lt;NA&gt;        48    131
##  3 bad           10 owner    36    46 married &lt;NA&gt;    free…       90    200
##  4 good           0 rent     60    24 single  no      fixed       63    182
##  5 good           0 rent     36    26 single  no      &lt;NA&gt;        46    107
##  6 good           1 owner    60    36 married no      &lt;NA&gt;        NA    214
##  7 good          29 owner    60    44 married no      fixed       75    125
##  8 good           9 pare…    12    27 &lt;NA&gt;    no      fixed       35     80
##  9 good           0 &lt;NA&gt;     60    32 married no      free…       90     NA
## 10 bad            0 pare…    48    41 married no      part…       90     80
## # … with 4,444 more rows, and 103 more variables: Assets &lt;int&gt;,
## #   Debt &lt;int&gt;, Amount &lt;int&gt;, Price &lt;int&gt;, Seniority1 &lt;int&gt;, Home1 &lt;fct&gt;,
## #   Time1 &lt;int&gt;, Age1 &lt;int&gt;, Marital1 &lt;fct&gt;, Records1 &lt;fct&gt;, Job1 &lt;fct&gt;,
## #   Expenses1 &lt;int&gt;, Income1 &lt;int&gt;, Assets1 &lt;int&gt;, Debt1 &lt;int&gt;,
## #   Amount1 &lt;int&gt;, Price1 &lt;int&gt;, Seniority2 &lt;int&gt;, Home2 &lt;fct&gt;,
## #   Time2 &lt;int&gt;, Age2 &lt;int&gt;, Marital2 &lt;fct&gt;, Records2 &lt;fct&gt;, Job2 &lt;fct&gt;,
## #   Expenses2 &lt;int&gt;, Income2 &lt;int&gt;, Assets2 &lt;int&gt;, Debt2 &lt;int&gt;,
## #   Amount2 &lt;int&gt;, Price2 &lt;int&gt;, Seniority11 &lt;int&gt;, Home11 &lt;fct&gt;,
## #   Time11 &lt;int&gt;, Age11 &lt;int&gt;, Marital11 &lt;fct&gt;, Records11 &lt;fct&gt;,
## #   Job11 &lt;fct&gt;, Expenses11 &lt;int&gt;, Income11 &lt;int&gt;, Assets11 &lt;int&gt;,
## #   Debt11 &lt;int&gt;, Amount11 &lt;int&gt;, Price11 &lt;int&gt;, CatNoise_1 &lt;fct&gt;,
## #   CatNoise_2 &lt;fct&gt;, CatNoise_3 &lt;fct&gt;, CatNoise_4 &lt;fct&gt;,
## #   CatNoise_5 &lt;fct&gt;, CatNoise_6 &lt;fct&gt;, CatNoise_7 &lt;fct&gt;,
## #   CatNoise_8 &lt;fct&gt;, CatNoise_9 &lt;fct&gt;, CatNoise_10 &lt;fct&gt;,
## #   CatNoise_11 &lt;fct&gt;, CatNoise_12 &lt;fct&gt;, CatNoise_13 &lt;fct&gt;,
## #   CatNoise_14 &lt;fct&gt;, CatNoise_15 &lt;fct&gt;, CatNoise_16 &lt;fct&gt;,
## #   CatNoise_17 &lt;fct&gt;, CatNoise_18 &lt;fct&gt;, CatNoise_19 &lt;fct&gt;,
## #   CatNoise_20 &lt;fct&gt;, CatNoise_21 &lt;fct&gt;, CatNoise_22 &lt;fct&gt;,
## #   CatNoise_23 &lt;fct&gt;, CatNoise_24 &lt;fct&gt;, CatNoise_25 &lt;fct&gt;,
## #   CatNoise_26 &lt;fct&gt;, CatNoise_27 &lt;fct&gt;, CatNoise_28 &lt;fct&gt;,
## #   CatNoise_29 &lt;fct&gt;, CatNoise_30 &lt;fct&gt;, NumNoise_1 &lt;dbl&gt;,
## #   NumNoise_2 &lt;dbl&gt;, NumNoise_3 &lt;dbl&gt;, NumNoise_4 &lt;dbl&gt;,
## #   NumNoise_5 &lt;dbl&gt;, NumNoise_6 &lt;dbl&gt;, NumNoise_7 &lt;dbl&gt;,
## #   NumNoise_8 &lt;dbl&gt;, NumNoise_9 &lt;dbl&gt;, NumNoise_10 &lt;dbl&gt;,
## #   NumNoise_11 &lt;dbl&gt;, NumNoise_12 &lt;dbl&gt;, NumNoise_13 &lt;dbl&gt;,
## #   NumNoise_14 &lt;dbl&gt;, NumNoise_15 &lt;dbl&gt;, NumNoise_16 &lt;dbl&gt;,
## #   NumNoise_17 &lt;dbl&gt;, NumNoise_18 &lt;dbl&gt;, NumNoise_19 &lt;dbl&gt;,
## #   NumNoise_20 &lt;dbl&gt;, NumNoise_21 &lt;dbl&gt;, NumNoise_22 &lt;dbl&gt;,
## #   NumNoise_23 &lt;dbl&gt;, NumNoise_24 &lt;dbl&gt;, NumNoise_25 &lt;dbl&gt;,
## #   NumNoise_26 &lt;dbl&gt;, NumNoise_27 &lt;dbl&gt;, …</code></pre>
</div>
<div id="testing-on-a-single-iteration" class="section level2">
<h2>Testing on a single iteration</h2>
<p>To check that everything is working as expected we test on a single iteration with 31 cores, no GPU, 1000 samples, 20 features and 50 trees.</p>
<pre class="r"><code>grid_test &lt;- benchmark_grid(complex_credit_data,
                            &quot;Status&quot;,
                            grid = spec_grid,
                            cores = 31, 
                            gpu = FALSE,
                            rowsample = 1e4,
                            trees = 50,
                            colsample = 20)</code></pre>
<pre><code>## 
## H2O is not running yet, starting it now...
## 
## Note:  In case of errors look at the following log files:
##     /tmp/RtmppdeaNe/h2o_seabbs_started_from_r.out
##     /tmp/RtmppdeaNe/h2o_seabbs_started_from_r.err
## 
## 
## Starting H2O JVM and connecting: . Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         1 seconds 213 milliseconds 
##     H2O cluster timezone:       Etc/UTC 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.23.0.4558 
##     H2O cluster version age:    5 days  
##     H2O cluster name:           H2O_started_from_R_seabbs_kha403 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   26.83 GB 
##     H2O cluster total cores:    32 
##     H2O cluster allowed cores:  31 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
##     R Version:                  R version 3.5.2 (2018-12-20) 
## 
## Trained a grid of 10 Xgboost models with 31 cores on a subsample of 10000 rows and 20 features with 50 trees.: 61.636 sec elapsed</code></pre>
<pre class="r"><code>grid_test</code></pre>
<pre><code>## $tic
## elapsed 
##   6.104 
## 
## $toc
## elapsed 
##   67.74 
## 
## $msg
## [1] &quot;Trained a grid of 10 Xgboost models with 31 cores on a subsample of 10000 rows and 20 features with 50 trees.&quot;
## 
## $fit
## [1] TRUE</code></pre>
<p>We see that the settings above give a runtime of around a minute but using the <code>htop</code> tool we see that resource use is not stable over time. This may indicate that <code>h2o</code> is not using all the supplied cores effectively/efficiently for this data size, with these settings etc.</p>
<div class="figure">
<img src="../../img/2019-01-20-benchmarking-workstation-xgboost/load-example.gif" alt="Load according to htop whilst running the test grid." />
<p class="caption">Load according to <code>htop</code> whilst running the test grid.</p>
</div>
</div>
<div id="enabling-gpu-support" class="section level2">
<h2>Enabling GPU support</h2>
<p>Unlike using CPUs for <code>xgboost</code>, enabling GPU support requires some extra steps (and lots of faff). As I have a Nvidia GPU, I need to install CUDA on my local machine (see <a href="https://www.samabbott.co.uk/post/building-an-rstats-workstation/">here</a> for details); CUDA 8.0 (or higher) into the Docker container that this analysis is running in (see here for <a href="https://github.com/seabbs/tidyverse-gpu">the Dockerfile</a> - thanks to <a href="https://discuss.ropensci.org/t/tips-for-installing-cuda-into-a-rocker-docker-container/1556">Noam Ross</a> for the original implementation); and run the Docker container using the <a href="https://github.com/NVIDIA/nvidia-docker">Nvidia Docker runtime</a>. To check everything is working, we run the same benchmark as above but now using the GPU.</p>
<pre class="r"><code>grid_test &lt;- benchmark_grid(complex_credit_data,
                            &quot;Status&quot;,
                            grid = spec_grid,
                            cores = 31, 
                            gpu = TRUE,
                            rowsample = 1e4,
                            trees = 50,
                            colsample = 20)</code></pre>
<pre><code>## 
## H2O is not running yet, starting it now...
## 
## Note:  In case of errors look at the following log files:
##     /tmp/RtmppdeaNe/h2o_seabbs_started_from_r.out
##     /tmp/RtmppdeaNe/h2o_seabbs_started_from_r.err
## 
## 
## Starting H2O JVM and connecting: . Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         1 seconds 86 milliseconds 
##     H2O cluster timezone:       Etc/UTC 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.23.0.4558 
##     H2O cluster version age:    5 days  
##     H2O cluster name:           H2O_started_from_R_seabbs_pon293 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   26.83 GB 
##     H2O cluster total cores:    32 
##     H2O cluster allowed cores:  31 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
##     R Version:                  R version 3.5.2 (2018-12-20) 
## 
## Trained a grid of 10 Xgboost models with 31 cores using the GPU backend on a subsample of 10000 rows and 20 features with 50 trees.: 236.803 sec elapsed</code></pre>
<pre class="r"><code>grid_test</code></pre>
<pre><code>## $tic
## elapsed 
##  73.641 
## 
## $toc
## elapsed 
## 310.444 
## 
## $msg
## [1] &quot;Trained a grid of 10 Xgboost models with 31 cores using the GPU backend on a subsample of 10000 rows and 20 features with 50 trees.&quot;
## 
## $fit
## [1] TRUE</code></pre>
<p>Success! However, it has a much longer run time of nearly 4 minutes - not good. We again see (this time using the <a href="https://github.com/Syllo/nvtop"><code>nvtop</code></a> tool) that resource use varies over time on the GPU.</p>
<div class="figure">
<img src="../../img/2019-01-20-benchmarking-workstation-xgboost/load-example-gpu.gif" alt="Load according to nvtop whilst running the test grid." />
<p class="caption">Load according to <code>nvtop</code> whilst running the test grid.</p>
</div>
</div>
<div id="iterating-across-a-grid" class="section level2">
<h2>Iterating Across a Grid</h2>
<p>Now that the timing function and the data are in place and everything is tested, I can run a full benchmarking grid. Using <code>expand.grid</code>, I’ve combined all combinations of data sizes from 1,000 to 100,000 rows, from 10 to 1000 columns, from 10 to 10,000 trees and compute availability (here 4, 16, and 32 cores + GPU). Something that I have not implemented here, but that would reduce the noise in the final results, is running each benchmark multiple times. As you will see below, this is not feasible for a weekend blog post (or even the week or two blog post that this finally became!). <em>Note: I ended up dropping the 1000 feature combinations for the GPU as for deep trees (<code>max_depth</code> = 10) I was getting out of memory errors.</em></p>
<ul>
<li>Grid set-up</li>
</ul>
<pre class="r"><code>benchmark_input &lt;- expand.grid(
  cores = c(4, 16, 32),
  rowsample = c(1e3, 1e4, 2.5e4, 5e4, 7.5e4, 1e5),
  colsample = c(10, 100, 1000),
  trees = c(10, 100, 1000, 10000),
  gpu = c(FALSE),
  rep = 1
) %&gt;% 
  as_tibble() %&gt;% 
  {bind_rows(., 
             filter(., cores == 4, colsample &lt; 1000) %&gt;% 
             mutate(gpu = TRUE))} %&gt;% 
  mutate(size = rowsample * colsample * trees) %&gt;% 
  arrange(desc(size), cores)

benchmark_input</code></pre>
<pre><code>## # A tibble: 264 x 7
##    cores rowsample colsample trees gpu     rep          size
##    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt;         &lt;dbl&gt;
##  1     4    100000      1000 10000 FALSE     1 1000000000000
##  2    16    100000      1000 10000 FALSE     1 1000000000000
##  3    32    100000      1000 10000 FALSE     1 1000000000000
##  4     4     75000      1000 10000 FALSE     1  750000000000
##  5    16     75000      1000 10000 FALSE     1  750000000000
##  6    32     75000      1000 10000 FALSE     1  750000000000
##  7     4     50000      1000 10000 FALSE     1  500000000000
##  8    16     50000      1000 10000 FALSE     1  500000000000
##  9    32     50000      1000 10000 FALSE     1  500000000000
## 10     4     25000      1000 10000 FALSE     1  250000000000
## # … with 254 more rows</code></pre>
<ul>
<li>Run benchmark - making use of <code>tibble</code> nesting and, the always slightly-hacky-feeling, <code>dplyr::rowwise</code>. Everything here is crudely cached to avoid accidentlly overwriting results.</li>
</ul>
<pre class="r"><code>## Cached manually to avoid rerunning on knit.
if (!file.exists(&quot;../../static/data/workstation-benchmark/xgboost.rds&quot;)) {
  benchmark_output_gpu &lt;- benchmark_input %&gt;% 
  rowwise() %&gt;% 
  mutate(bench = list(as_tibble(benchmark_grid(complex_credit_data,
                                       &quot;Status&quot;,
                                        grid = spec_grid,
                                        cores = cores, 
                                        gpu = gpu,
                                        rowsample = rowsample,
                                        trees = trees,
                                        colsample = colsample)))) %&gt;% 
  unnest(bench) %&gt;%
  select(-msg) %&gt;% 
  mutate(duration = toc - tic) %&gt;% 
  filter(fit)
  
  saveRDS(benchmark_output, &quot;../../static/data/workstation-benchmark/xgboost.rds&quot;)
}else{
  benchmark_output &lt;- readRDS( &quot;../../static/data/workstation-benchmark/xgboost.rds&quot;)
}

benchmark_output &lt;- benchmark_output %&gt;% 
  mutate(duration = duration / 60) %&gt;% 
  arrange(gpu, cores) %&gt;% 
  mutate(Compute = paste0(cores, &quot; Threadripper 1950X CPU cores&quot;) %&gt;% 
           ifelse(gpu, &quot;Nvidia 2070 GPU&quot;, .))</code></pre>
</div>
<div id="benchmarking-results" class="section level2">
<h2>Benchmarking Results</h2>
<p>After leaving everything running for a few days, the results are in. The obvious plot to begin with is to split out everything by the number of trees and features and then plot duration against sample numbers for each compute amount (i.e cores and GPU).</p>
<pre class="r"><code>benchmark_output %&gt;% 
  mutate(Cores = factor(cores),
         GPU = gpu) %&gt;% 
  ggplot(aes(rowsample, duration, col = Cores, shape = GPU, group = interaction(Cores, GPU))) +
  geom_point(size = 1.2) +
  geom_line(alpha = 0.8) + 
  facet_grid(colsample ~ trees, scales = &quot;free_y&quot;) +
  theme_minimal() +
  theme(legend.position = &quot;top&quot;, axis.text.x = element_text(angle = 90,hjust = 1)) +
  scale_x_continuous(labels = scales::comma) + 
  scale_color_viridis_d(end = 0.9, begin = 0.1) +
  labs(x = &quot;Rows&quot;,
       y = &quot;Duration (minutes)&quot;,
       caption = &quot;Number of Trees ~ Number of Features&quot;, 
       title = &quot;Xgboost via h2o: Duration&quot;,
       subtitle = &quot;10 model hyper-parameter grid search with 5 fold cross-validation&quot;)</code></pre>
<p><img src="../../post/2019-01-26-benchmarking-workstation-xgboost_files/figure-html/unnamed-chunk-11-1.png" width="3200" /></p>
<p>So the first major takeaway is that using the GPU appears to be slower, and mostly much slower, than using 4 CPU cores. This is very surprising to me as everything I have seen elsewhere would indicate that the GPU should offer some substantial speed up. There are some indications however that for larger data sets, and for larger tree numbers, the GPU may be comparable to multiple CPU cores. Potentially this is because any computational benefit from using the GPU is being swamped by the overhead of constantly passing data. Therefore, as the complexity of the problem increases so does the potential benefits of using the GPU. We see something similar for increasing the CPU count, with grids with 10 features running in nearly the same time for 4, 16 and 32 cores, whilst grids with 1000 features are drastically slower on 4 CPUs vs 16. Across all tests it looks like there is little benefit from using 32 (with 16 virtual) over 16 cores.</p>
<p>To get a closer look at the CPU results and to try and understand the magnitude of the results, I’ve plotted the percentage improvement from a given compute amount over the longest duration for that number of rows - filtering out the GPU results as these would otherwise mask any other findings.</p>
<pre class="r"><code>benchmark_output %&gt;% 
  filter(!gpu) %&gt;% 
  group_by(rowsample, colsample, trees) %&gt;% 
  mutate(duration = (max(duration) - duration) / max(duration)) %&gt;% 
  mutate(Cores = factor(cores)) %&gt;%
  ggplot(aes(rowsample, duration, duration, col = Cores)) +
  geom_point(size = 1.2) +
  geom_line(alpha = 0.8) + 
  facet_grid(colsample ~ trees, scales = &quot;free_y&quot;) +
  theme_minimal() +
  theme(legend.position = &quot;top&quot;, axis.text.x = element_text(angle=90,hjust=1)) +
  scale_y_continuous(labels = scales::percent) +
  scale_x_continuous(labels = scales::comma) + 
  scale_color_viridis_d(begin = 0.2, end = 0.8) +
  labs(x = &quot;Rows&quot;,
       y = &quot;Performance improvement over baseline (%)&quot;,
       caption = &quot;Number of Trees ~ Number of Features&quot;,
              title = &quot;Xgboost via h2o: Performance over baseline&quot;,
       subtitle = &quot;10 model hyper-parameter grid search with 5 fold cross-validation&quot;)</code></pre>
<p><img src="../../post/2019-01-26-benchmarking-workstation-xgboost_files/figure-html/unnamed-chunk-13-1.png" width="3200" /></p>
<p>For 10 features, the results are very noisy with 4 cores being comparable until 10,000 trees are used. For both 100 and 1000 features, 16 (+32) cores are superior across the board with a near linear speed up as the number of samples increases. Whilst we might imagine that increasing core count from 4 to 16 should result in a near 4 times speed up (or a 75% improvment in performance), interestingly, we are only really see anywhere near this performance with over 50,000 rows, 10000 trees, and 1000 features. This is probably because <code>h2o</code> is parallelised on the model level (- this is conjecture based on observing <code>htop</code>), which means that for each fold of each model all the data has to be transferred between cores leading to a large overhead. In most of these test cases, the overhead of passing data and setting up jobs is taking up much of the potential benefit from additional cores. This leads to only a 2-3 times speed up. It’s likely that in larger data sets, with longer compute times, this would be less of an issue.</p>
</div>
<div id="wrap-up" class="section level2">
<h2>Wrap up</h2>
<p>In this post, I have looked at the performance of <code>xgboost</code> via <code>h2o</code> on a sample data set, using a real-world test case of a cross-validated grid search. I found that using the GPU resulted in slower run times across the board, although there was some indication that performance improved for larger data and more complex models. Increasing the physical CPU count to 16 increased performance up to a maximum of 70% over 4 cores (for 100,000 features, 1000 features and 10,000 trees) but adding virtual cores led to no benefit.</p>
<p>A major takeaway for me is that I probably shouldn’t be relying on <code>h2o</code> for my grid searching in future when using smaller data sets. Something to experiment with would be parallelising across the grid, with each model using a single core. Having very much swallowed the Kool-Aid when it comes GPU compute, I was also surprised by how poor the performance was here. This is something to test further as using <code>xgboost</code> within <code>h2o</code> makes it difficult to pick apart where the problem lies. A test with a larger data set would also be helpful, although this may take awhile to run!</p>
<p>Any thoughts on these results would be appreciated, especially regarding the poor performance of the GPU. I am also in the market for a new ML toolbox. I’ve been looking at <a href="https://github.com/mlr-org/mlr"><code>mlr</code></a> so any recommendations would be appreciated. I’ll be following this post up with another benchmarking post using <code>benchmarkme</code> in the next few days - if I can resist turning off virtual cores and getting going with some more overclocking.</p>
</div>

    </div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="../../tags/benchmark">benchmark</a>
  
  <a class="btn btn-primary btn-outline" href="../../tags/cpu">cpu</a>
  
  <a class="btn btn-primary btn-outline" href="../../tags/gpu">gpu</a>
  
  <a class="btn btn-primary btn-outline" href="../../tags/data-science">data science</a>
  
  <a class="btn btn-primary btn-outline" href="../../tags/xgboost">xgboost</a>
  
  <a class="btn btn-primary btn-outline" href="../../tags/h2o">h2o</a>
  
  <a class="btn btn-primary btn-outline" href="../../tags/workstation">workstation</a>
  
</div>




    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="../../post/building-an-rstats-workstation/">Building an Rstats Workstation</a></li>
        
      </ul>
    </div>
    

    

    
<section id="comments">
  <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "samabbott-co-uk" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



  </div>
</article>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 Sam Abbott &middot; 
  
      Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic
      theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a> &middot;
      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>
        
    
    
    
    
      
    
    
     <a href="https://github.com/seabbs/seabbs.github.io/tree/sources/content/post/2019-01-26-benchmarking-workstation-xgboost.Rmd">Edit this page.</a>
    
   
    </p>
  </div>
</footer>

    

    
    
    <script id="dsq-count-scr" src="//samabbott-co-uk.disqus.com/count.js" async></script>
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="../../js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/bash.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/cs.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/http.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/javascript.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/json.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/markdown.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/xml.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

